<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Bed-Time Story Generator</title>

  <!-- ONNX Runtime Web from CDN -->
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
  <script>
    // point to the CDN WASM files
    ort.env.wasm.wasmPaths = {
      "ort-wasm.wasm":               "https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort-wasm.wasm",
      "ort-wasm-simd.wasm":          "https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort-wasm-simd.wasm",
      "ort-wasm-threaded.wasm":      "https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort-wasm-threaded.wasm",
      "ort-wasm-simd-threaded.wasm": "https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort-wasm-simd-threaded.wasm"
    };
  </script>

  <style>
    body { font-family: sans-serif; padding: 2em; }
    textarea { width: 100%; box-sizing: border-box; }
    button { margin-top: .5em; padding: .5em 1em; }
    pre { background: #f4f4f4; padding: 1em; white-space: pre-wrap; }
  </style>
</head>
<body>
  <h1>Bed-Time Story Generator</h1>
  <textarea id="prompt" rows="4" placeholder="Once upon a time…"></textarea><br>
  <button id="generate">Tell me a story!</button>
  <pre id="story"></pre>

  <script>
    // load the with-past ONNX model
    const sessionPromise = ort.InferenceSession.create(
      "./models/TinyStories-Instruct-1M/TinyStories-Instruct-1M.onnx",
      { executionProviders: ["wasm"] }
    );

    async function generateStory(promptText, maxNewTokens = 64) {
      const session = await sessionPromise;
      const encoder = new TextEncoder();
      const decoder = new TextDecoder();

      // 4. initial prompt → token IDs & mask
      let inputIds = Array.from(encoder.encode(promptText));
      let attentionMask = Array(inputIds.length).fill(1);

      // 5. find all the cache inputs
      const cacheInputNames = session.inputNames.filter(n =>
        n.startsWith("past_key_values.")
      );

      // 6. seed each cache input with a [1,16,4,0] float32 tensor
      const pastFeeds = {};
      for (let name of cacheInputNames) {
        pastFeeds[name] = new ort.Tensor(
          "float32",
          new Float32Array(0),
          [1, 16, 4, 0]
        );
      }

      const generated = [];

      for (let step = 0; step < maxNewTokens; step++) {
        // 7. build feeds object
        const feeds = {
          input_ids:      new ort.Tensor("int32", Int32Array.from(inputIds),        [1, inputIds.length]),
          attention_mask: new ort.Tensor("int32", Int32Array.from(attentionMask),   [1, attentionMask.length]),
          ...pastFeeds
        };

        // 8. run one autoregressive step
        const outputs = await session.run(feeds);

        // 9. greedy pick next token
        const logits = outputs.logits.data;
        let maxLogit = -Infinity, nextId = 0;
        for (let i = 0; i < logits.length; i++) {
          if (logits[i] > maxLogit) {
            maxLogit = logits[i];
            nextId = i;
          }
        }
        generated.push(nextId);

        // 10. prepare for next iteration
        inputIds = [ nextId ];
        attentionMask = [ 1 ];

        // swap in the new cache
        for (let name in outputs) {
          if (name.startsWith("present_key_values.")) {
            pastFeeds[name.replace("present_key_values", "past_key_values")] = outputs[name];
          }
        }
      }

      // decode and return
      return decoder.decode(new Uint8Array(generated));
    }

    document.getElementById("generate").onclick = async () => {
      const prompt = document.getElementById("prompt").value.trim() || "Once upon a time";
      document.getElementById("story").textContent = "⏳ Generating…";
      const continuation = await generateStory(prompt, 128);
      document.getElementById("story").textContent = prompt + continuation;
    };
  </script>
</body>
</html>
