<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Bed-Time Story Generator</title>

  <!-- 1. Load ONNX Runtime Web from CDN -->
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
  <script>
    // 2. Point the four WASM backends to the CDN so no local files are needed.
    ort.env.wasm.wasmPaths = {
      "ort-wasm.wasm":               "https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort-wasm.wasm",
      "ort-wasm-simd.wasm":          "https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort-wasm-simd.wasm",
      "ort-wasm-threaded.wasm":      "https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort-wasm-threaded.wasm",
      "ort-wasm-simd-threaded.wasm": "https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort-wasm-simd-threaded.wasm"
    };
  </script>

  <style>
    body { font-family: sans-serif; padding: 2em; }
    textarea { width: 100%; box-sizing: border-box; }
    button { margin-top: .5em; padding: .5em 1em; }
    pre { background: #f4f4f4; padding: 1em; white-space: pre-wrap; }
  </style>
</head>
<body>
  <h1>Bed-Time Story Generator</h1>
  <textarea id="prompt" rows="4" placeholder="Once upon a time…"></textarea><br>
  <button id="generate">Tell me a story!</button>
  <pre id="story"></pre>

  <script>
    // 3. Load your “with-past” ONNX model
    const sessionPromise = ort.InferenceSession.create(
      "./models/TinyStories-Instruct-1M/TinyStories-Instruct-1M.onnx",
      { executionProviders: ["wasm"] }
    );

    async function generateStory(promptText, maxNewTokens = 64) {
      const session = await sessionPromise;
      const encoder = new TextEncoder();
      const decoder = new TextDecoder();

      // 4. Initial tokens & mask from the prompt
      let inputIds = Array.from(encoder.encode(promptText));
      let attentionMask = Array(inputIds.length).fill(1);

      // 5. Discover all the cache input names
      const cacheInputNames = session.inputNames.filter(name =>
        name.startsWith("past_key_values.")
      );

      // 6. Build initial zero-length past_key_values tensors
      const pastFeeds = {};
      for (let name of cacheInputNames) {
        // shape: [1, num_heads, head_dim, 0]
        // We don't know num_heads/head_dim here, but ONNX Runtime
        // will accept 0-length last dim for first step.
        pastFeeds[name] = new ort.Tensor(
          "float32",
          new Float32Array(0),
          // the rank must match the exported graph; typically [1,?, ?, 0]
          [1, /*num_heads*/, /*head_dim*/, 0]
        );
      }

      const generated = [];

      for (let step = 0; step < maxNewTokens; step++) {
        // 7. Prepare feeds: inputs + past cache
        const feeds = {
          input_ids:      new ort.Tensor("int32", Int32Array.from(inputIds),      [1, inputIds.length]),
          attention_mask: new ort.Tensor("int32", Int32Array.from(attentionMask), [1, attentionMask.length]),
          ...pastFeeds
        };

        // 8. Run the model for one step
        const outputs = await session.run(feeds);

        // 9. Greedy decode: pick the highest-logit token
        const logits = outputs.logits.data;             // shape [1, vocab_size]
        let maxLogit = -Infinity, nextId = 0;
        for (let i = 0; i < logits.length; i++) {
          if (logits[i] > maxLogit) {
            maxLogit = logits[i];
            nextId = i;
          }
        }
        generated.push(nextId);

        // 10. Prepare for next iteration:
        //    - Only feed the new token next time
        //    - Attention mask of [1]
        inputIds = [ nextId ];
        attentionMask = [ 1 ];

        //    - Replace past_key_values.* with present_key_values.*
        for (let name in outputs) {
          if (name.startsWith("present_key_values.")) {
            const pastName = name.replace("present_key_values", "past_key_values");
            pastFeeds[pastName] = outputs[name];
          }
        }
      }

      // 11. Decode generated IDs to string
      return decoder.decode(new Uint8Array(generated));
    }

    document.getElementById("generate").onclick = async () => {
      const prompt = document.getElementById("prompt").value.trim() || "Once upon a time";
      document.getElementById("story").textContent = "⏳ Generating…";
      const continuation = await generateStory(prompt, 128);
      document.getElementById("story").textContent = prompt + continuation;
    };
  </script>
</body>
</html>
